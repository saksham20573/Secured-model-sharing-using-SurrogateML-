{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "04tzY4mE-Efa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycl1rfOuNYgN",
        "outputId": "a13f311b-cb14-4b41-d216-afc86ec19c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "093l2xRbfanv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORvBfQtf6TY1"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Tn_WDgdVFx"
      },
      "outputs": [],
      "source": [
        "class TreeNode:\n",
        "  def __init__(self, best_split, X, y, left_node = None, right_node = None, left_prob = 0, right_prob = 0, isLeaf = False):\n",
        "\n",
        "    # This variable contains the prediction in case this node is the leaf\n",
        "    self.best_split = best_split\n",
        "    self.left_node = left_node\n",
        "    self.right_node = right_node\n",
        "    self.left_prob = left_prob\n",
        "    self.right_prob = right_prob\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.isLeaf = isLeaf\n",
        "\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None, randomWalkIter = 100):\n",
        "        self.max_depth = max_depth\n",
        "        self.randomWalkIter = randomWalkIter\n",
        "\n",
        "\n",
        "    def calculate_feature_importance(self):\n",
        "      n = self.randomWalkIter\n",
        "      self.importance_dict = {}\n",
        "      for i in self.train_features:\n",
        "        self.importance_dict[i] = 0\n",
        "\n",
        "      for _ in range(n):\n",
        "        self.run_random_walk()\n",
        "\n",
        "      for i in self.importance_dict.keys():\n",
        "        self.importance_dict[i] /= n\n",
        "      # print(n)\n",
        "\n",
        "    def run_random_walk(self):\n",
        "      steps = 0\n",
        "      temp = copy.deepcopy(self.importance_dict)\n",
        "      for i in temp.keys():\n",
        "        temp[i] = 0\n",
        "      tree = copy.deepcopy(self.treeNode)\n",
        "      while True:\n",
        "        if tree.isLeaf:\n",
        "          break\n",
        "        temp[self.train_features[tree.best_split[0]]] += 1\n",
        "        steps += 1\n",
        "        if tree.left_node != None and tree.right_node != None:\n",
        "          tree = random.choices([tree.left_node, tree.right_node], weights=[tree.left_prob, tree.right_prob])[0]\n",
        "        else:\n",
        "          tree = random.choice([tree.left_node, tree.right_node])\n",
        "      for i in self.importance_dict.keys():\n",
        "        self.importance_dict[i] += (temp[i] / steps)\n",
        "\n",
        "    def get_max_corr(self, X_train, y_train, feat):\n",
        "      df = X_train.copy()\n",
        "      df_in = X_train.copy()\n",
        "      y_train = y_train.copy()\n",
        "      drop_list = []\n",
        "      for i in df_in.columns:\n",
        "        if i not in self.prediction_feature_list and i != feat:\n",
        "          drop_list.append(i)\n",
        "\n",
        "      df = df.drop(drop_list, axis=1)\n",
        "      lst = dict(abs(df.corr()[feat]))\n",
        "      del lst[feat]\n",
        "      df = df.drop(feat, axis=1)\n",
        "      df['label'] = y_train\n",
        "      label_lst = dict(abs(df.corr()['label']))\n",
        "      del label_lst[\"label\"]\n",
        "\n",
        "\n",
        "      final_dict = {}\n",
        "      for i in lst:\n",
        "        final_dict[i] = lst[i] + label_lst[i]\n",
        "      sorted_corr = sorted(final_dict.items(), key = lambda x : x[1], reverse = True)\n",
        "      return sorted_corr\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      self.train_features = list(X.columns)\n",
        "      self.X_train = X.copy()\n",
        "      self.y_train = y.copy()\n",
        "      self.tree, self.treeNode = self._grow_tree(X.to_numpy(), y.to_numpy())\n",
        "      self.calculate_feature_importance()\n",
        "\n",
        "    def get_best_split(self, feature, X):\n",
        "      feature_idx = self.train_features.index(feature)\n",
        "      best_gini = np.inf\n",
        "      best_split = None\n",
        "      best_left_indices = None\n",
        "      best_right_indices = None\n",
        "      thresholds = np.unique(X[:, feature_idx])\n",
        "      for threshold in thresholds:\n",
        "          left_indices = np.where(X[:, feature_idx] <= threshold)[0]\n",
        "          right_indices = np.where(X[:, feature_idx] > threshold)[0]\n",
        "\n",
        "          if len(left_indices) == 0 or len(right_indices) == 0:\n",
        "              continue\n",
        "\n",
        "          gini = self._gini_impurity(y[left_indices], y[right_indices])\n",
        "\n",
        "          if gini < best_gini:\n",
        "              best_gini = gini\n",
        "              best_split = (feature_idx, threshold)\n",
        "              best_left_indices = left_indices\n",
        "              best_right_indices = right_indices\n",
        "      return best_split\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        num_samples, num_features = X.shape\n",
        "        num_classes = len(np.unique(y))\n",
        "\n",
        "        # Stopping criteria\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or num_classes == 1:\n",
        "            final_class = int(np.bincount(y).argmax())\n",
        "            return final_class, TreeNode(final_class, X = X, y = y, isLeaf=True)\n",
        "\n",
        "        # Select the best split\n",
        "        best_gini = np.inf\n",
        "        best_split = None\n",
        "        best_left_indices = None\n",
        "        best_right_indices = None\n",
        "\n",
        "        for feature_idx in range(num_features):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = np.where(X[:, feature_idx] <= threshold)[0]\n",
        "                right_indices = np.where(X[:, feature_idx] > threshold)[0]\n",
        "\n",
        "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
        "                    continue\n",
        "\n",
        "                gini = self._gini_impurity(y[left_indices], y[right_indices])\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_split = (feature_idx, threshold)\n",
        "                    best_left_indices = left_indices\n",
        "                    best_right_indices = right_indices\n",
        "\n",
        "        if best_gini == np.inf:\n",
        "            final_class = int(np.bincount(y).argmax())\n",
        "            return final_class, TreeNode(final_class, X = X, y = y, isLeaf=True)\n",
        "\n",
        "\n",
        "        left_subtree, leftNode = self._grow_tree(X[best_left_indices], y[best_left_indices], depth + 1)\n",
        "        right_subtree, rightNode = self._grow_tree(X[best_right_indices], y[best_right_indices], depth + 1)\n",
        "\n",
        "        currNode = TreeNode(best_split, X = X, y = y, left_node = leftNode, right_node = rightNode, left_prob = len(X[best_left_indices]) / len(X), right_prob = len(X[best_right_indices])/ len(X))\n",
        "\n",
        "        return (best_split, left_subtree, right_subtree), currNode\n",
        "\n",
        "    def _gini_impurity(self, left_y, right_y):\n",
        "        p_left = len(left_y) / (len(left_y) + len(right_y))\n",
        "        p_right = len(right_y) / (len(left_y) + len(right_y))\n",
        "        gini_left = 1 - sum((np.bincount(left_y) / len(left_y))**2)\n",
        "        gini_right = 1 - sum((np.bincount(right_y) / len(right_y))**2)\n",
        "        gini = p_left * gini_left + p_right * gini_right\n",
        "        return gini\n",
        "\n",
        "\n",
        "    def get_inp_count(self, inp, X_train):\n",
        "      drop_cols = []\n",
        "      X_train = X_train.reset_index(drop = True)\n",
        "      for i in list(X_train.columns):\n",
        "        if i not in self.prediction_feature_list:\n",
        "          drop_cols.append(i)\n",
        "      X_train = X_train.drop(drop_cols, axis=1)\n",
        "      occ_count = 0\n",
        "\n",
        "      for i in X_train.index:\n",
        "        flag = True\n",
        "        for col in list(inp.columns):\n",
        "          threshold = (max(X_train[col]) - min(X_train[col])) / 20\n",
        "          if abs(inp[col][0] - X_train[col][i]) > threshold:\n",
        "            flag = False\n",
        "            break\n",
        "        if flag:\n",
        "          occ_count += 1\n",
        "      return occ_count\n",
        "\n",
        "    def get_counts(self, inp, left_data, right_data, correlated_features):\n",
        "      left_count, right_count = 0, 0\n",
        "      iter = 0\n",
        "\n",
        "      drop_cols = []\n",
        "      left_data = left_data.reset_index(drop = True)\n",
        "      right_data = right_data.reset_index(drop = True)\n",
        "      for i in list(left_data.columns):\n",
        "        if i not in self.prediction_feature_list:\n",
        "          drop_cols.append(i)\n",
        "      left_data = left_data.drop(drop_cols, axis=1)\n",
        "      right_data = right_data.drop(drop_cols, axis=1)\n",
        "\n",
        "      inp_left = tuple(np.array(inp) / (left_data.max().to_numpy() - left_data.min().to_numpy() + 1e-10))\n",
        "      inp_right = tuple(np.array(inp) / (right_data.max().to_numpy()  - right_data.min().to_numpy() + 1e-10))\n",
        "\n",
        "\n",
        "      left_diff = np.abs(right_data - inp) / (left_data.max().to_numpy() - left_data.min().to_numpy() + 1e-10)\n",
        "      right_diff = np.abs(right_data - inp) / (right_data.max().to_numpy()  - right_data.min().to_numpy() + 1e-10)\n",
        "      tolerance = 0.05\n",
        "      out_left = (left_diff <= tolerance).all(axis=1)\n",
        "      out_right = (right_diff <= tolerance).all(axis=1)\n",
        "\n",
        "      left_count = out_left.sum()\n",
        "      right_count = out_right.sum()\n",
        "\n",
        "      return left_count + 1, right_count + 1\n",
        "\n",
        "    def predict(self, X):\n",
        "      self.prediction_feature_list = list(X.columns)\n",
        "      return np.array([self._predict_single(x, self.tree, self.treeNode, list(X.columns))[0] for x in tqdm(X.to_numpy())])\n",
        "\n",
        "    def _predict_single(self, x, tree, treeNode, inp_cols):\n",
        "        if isinstance(tree, int) or treeNode.isLeaf:\n",
        "            return tree, treeNode\n",
        "\n",
        "        feature_idx, threshold = tree[0]\n",
        "        best_feature_name = self.train_features[feature_idx]\n",
        "        inp_df = pd.DataFrame([list(x)], columns=self.prediction_feature_list)\n",
        "\n",
        "        # Logic to handle missing feature\n",
        "        if best_feature_name not in self.prediction_feature_list:\n",
        "          X_t = pd.DataFrame(treeNode.X, columns = self.train_features)\n",
        "          y_t = pd.Series(treeNode.y)\n",
        "          correlated_features = self.get_max_corr(X_t, y_t, best_feature_name)\n",
        "          left_weighted_sum = 0\n",
        "          right_weighted_sum  = 0\n",
        "          normalization_factor = 0\n",
        "          for feat, _ in correlated_features[:3]:\n",
        "            out = self.get_best_split(feat, treeNode.X)\n",
        "            if out == None:\n",
        "              continue\n",
        "            _, threshold = out\n",
        "            left_data = X_t[X_t[feat] <= threshold].reset_index(drop=True)\n",
        "            right_data = X_t[X_t[feat] > threshold].reset_index(drop=True)\n",
        "            dropped_x = list(x)\n",
        "            dropped_x.pop(inp_cols.index(feat))\n",
        "            left_count, right_count = self.get_counts(np.array(dropped_x), left_data.drop(feat, axis = 1), right_data.drop(feat, axis = 1), correlated_features)\n",
        "            left_weighted_sum += (self.importance_dict[feat]*left_count*treeNode.left_prob)\n",
        "            right_weighted_sum += (self.importance_dict[feat]*right_count*treeNode.right_prob)\n",
        "            normalization_factor += self.importance_dict[feat]\n",
        "\n",
        "          left_dec = left_weighted_sum / (normalization_factor + 1)\n",
        "          right_dec = right_weighted_sum / (normalization_factor + 1)\n",
        "\n",
        "          if left_dec >= right_dec:\n",
        "            return self._predict_single(x, tree[1], treeNode.left_node, inp_cols)\n",
        "          else:\n",
        "            return self._predict_single(x, tree[2], treeNode.right_node, inp_cols)\n",
        "\n",
        "        elif inp_df[best_feature_name][0] <= threshold:\n",
        "            return self._predict_single(x, tree[1], treeNode.left_node, inp_cols)\n",
        "        else:\n",
        "            return self._predict_single(x, tree[2], treeNode.right_node, inp_cols)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ-qMJ0ZmCdM"
      },
      "outputs": [],
      "source": [
        "def run_smaller_model(X_train, X_test, y_train, y_test):\n",
        "  model = DecisionTree(max_depth=5)\n",
        "  model.fit(X_train, y_train)\n",
        "  preds = model.predict(X_test)\n",
        "  print(classification_report(y_test, preds, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46L1li_gyvnE"
      },
      "outputs": [],
      "source": [
        "def run_imputation_model(model, X_train, X_test, y_train, y_test, dropped_columns):\n",
        "  X_test_final = X_test.copy()\n",
        "  while len(dropped_columns) != 0:\n",
        "    clf = DecisionTree(max_depth=5)\n",
        "    y_train_temp = X_train[dropped_columns[0]]\n",
        "    # print(y_train[:10])\n",
        "    if min(y_train_temp) < 0:\n",
        "      y_train_temp += abs(min(y_train_temp))\n",
        "    X_train_temp = X_train.drop(dropped_columns, axis=1)\n",
        "    # print(X_train_temp.head())\n",
        "    clf.fit(X_train_temp, y_train_temp)\n",
        "    X_test_final[dropped_columns[0]] = clf.predict(X_test_final)\n",
        "    dropped_columns.pop(0)\n",
        "  predictions = model.predict(X_test_final)\n",
        "  print(classification_report(y_test, predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4bqr2lMGxb5"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "def run_imputation_sklearn(model, X_train, X_test, y_train, y_test, dropped_columns, criterion=\"absolute_error\"):\n",
        "    X_test_final = X_test.copy()\n",
        "    while len(dropped_columns) != 0:\n",
        "      clf = DecisionTreeRegressor(max_depth=3, criterion=criterion)\n",
        "      y_train_temp = X_train[dropped_columns[0]]\n",
        "      if min(y_train_temp) < 0:\n",
        "        y_train_temp += abs(min(y_train_temp))\n",
        "      X_train_temp = X_train.drop(dropped_columns, axis=1)\n",
        "      clf.fit(X_train_temp, y_train_temp)\n",
        "      X_test_final[dropped_columns[0]] = clf.predict(X_test_final)\n",
        "      dropped_columns.pop(0)\n",
        "    predictions = model.predict(X_test_final)\n",
        "    print(classification_report(y_test, predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao8P2fCqPYfc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_imputation_credit(model, X_train, X_test, y_train, y_test, dropped_columns):\n",
        "    X_test_final = X_test.copy()\n",
        "    while len(dropped_columns) != 0:\n",
        "      if dropped_columns[0] == \"BILL_AMT1\":\n",
        "        clf = DecisionTreeRegressor(max_depth=3)\n",
        "      else:\n",
        "        clf = DecisionTree(max_depth=5)\n",
        "      y_train_temp = X_train[dropped_columns[0]]\n",
        "      if min(y_train_temp) < 0:\n",
        "        y_train_temp += abs(min(y_train_temp))\n",
        "      X_train_temp = X_train.drop(dropped_columns, axis=1)\n",
        "      clf.fit(X_train_temp, y_train_temp)\n",
        "      X_test_final[dropped_columns[0]] = clf.predict(X_test_final)\n",
        "      dropped_columns.pop(0)\n",
        "    predictions = model.predict(X_test_final)\n",
        "    print(classification_report(y_test, predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnKAOXD9-mL6"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Te-hHGKmJd7"
      },
      "outputs": [],
      "source": [
        "def print_tree(train_features, node):\n",
        "  if node.isLeaf:\n",
        "    return\n",
        "  else:\n",
        "    print(train_features[node.best_split[0]])\n",
        "    print_tree(train_features, node.left_node)\n",
        "    print_tree(train_features, node.right_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKwKaE4chWbr"
      },
      "source": [
        "## Credit card"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCaGcH9riY2B"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Credit_card.csv\")\n",
        "label = 'default payment next month'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPw5V6TIhv1P"
      },
      "outputs": [],
      "source": [
        "X = df.drop(label, axis=1)\n",
        "y = df[label]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5gv6YKThaIW"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTree(max_depth=5)\n",
        "clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqO99X76FzyZ"
      },
      "outputs": [],
      "source": [
        "print_tree(clf.train_features, clf.treeNode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krM6aaw3LvMj",
        "outputId": "2b08663e-942e-4081-e64a-269222e20cc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([    1,     2,     3, ..., 29998, 29999, 30000])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['ID'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yFg00eFd1RT"
      },
      "outputs": [],
      "source": [
        "X_test = X_test.iloc[:1000, :]\n",
        "y_test = y_test[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original model"
      ],
      "metadata": {
        "id": "KdU72AJ4-qah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuXm58iMBsjK",
        "outputId": "7c0c16f5-9fa9-4725-db61-d5b517b951d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 206.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8265    0.9476    0.8829       764\n",
            "           1     0.6774    0.3559    0.4667       236\n",
            "\n",
            "    accuracy                         0.8080      1000\n",
            "   macro avg     0.7520    0.6518    0.6748      1000\n",
            "weighted avg     0.7913    0.8080    0.7847      1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "predictions  = clf.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ordinal"
      ],
      "metadata": {
        "id": "6j37LxqM-MW_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLsixXegsfAf"
      },
      "outputs": [],
      "source": [
        "X_test_temp = X_test.drop(\"PAY_0\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryoi6o3UstKD",
        "outputId": "7d80c29b-e644-414d-a61d-b29b015dbf85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [04:29<00:00,  3.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7822    0.9777    0.8691       764\n",
            "           1     0.6222    0.1186    0.1993       236\n",
            "\n",
            "    accuracy                         0.7750      1000\n",
            "   macro avg     0.7022    0.5482    0.5342      1000\n",
            "weighted avg     0.7444    0.7750    0.7110      1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "predictions  = clf.predict(X_test_temp.reset_index(drop=True))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG99fUesv5tK",
        "outputId": "034e0b1c-fdf7-4f65-edcf-f9cbd3dc7610"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:03<00:00, 261.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8013    0.9503    0.8695       764\n",
            "           1     0.5957    0.2373    0.3394       236\n",
            "\n",
            "    accuracy                         0.7820      1000\n",
            "   macro avg     0.6985    0.5938    0.6044      1000\n",
            "weighted avg     0.7528    0.7820    0.7444      1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_smaller_model(X_train.drop(\"PAY_0\", axis=1), X_test_temp, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjc_xVCa3Omo",
        "outputId": "1de99dd1-71fd-48eb-a2e8-b2ab34895b3a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:03<00:00, 297.10it/s]\n",
            "100%|██████████| 1000/1000 [00:04<00:00, 249.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8159    0.3770    0.5157       764\n",
            "           1     0.2643    0.7246    0.3873       236\n",
            "\n",
            "    accuracy                         0.4590      1000\n",
            "   macro avg     0.5401    0.5508    0.4515      1000\n",
            "weighted avg     0.6857    0.4590    0.4854      1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_imputation_model(clf, X_train, X_test.drop(\"PAY_0\", axis=1).iloc[:1000, :], y_train, y_test[:1000], [\"PAY_0\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numeric"
      ],
      "metadata": {
        "id": "T_Q380ty-b5T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HX5JiAI6Dix",
        "outputId": "15a2ece3-8190-4921-8a95-9e229f704a39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [46:24<00:00,  2.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8265    0.9476    0.8829       764\n",
            "           1     0.6774    0.3559    0.4667       236\n",
            "\n",
            "    accuracy                         0.8080      1000\n",
            "   macro avg     0.7520    0.6518    0.6748      1000\n",
            "weighted avg     0.7913    0.8080    0.7847      1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "X_test_temp = X_test.drop(\"BILL_AMT1\", axis=1)\n",
        "predictions  = clf.predict(X_test_temp.reset_index(drop=True))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXkpUPR-qAx9",
        "outputId": "8f0802dd-754e-44a4-8242-a1431609c733"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 223.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7817    0.9751    0.8678       764\n",
            "           1     0.5957    0.1186    0.1979       236\n",
            "\n",
            "    accuracy                         0.7730      1000\n",
            "   macro avg     0.6887    0.5469    0.5328      1000\n",
            "weighted avg     0.7378    0.7730    0.7097      1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_smaller_model(X_train.drop(\"BILL_AMT1\", axis=1), X_test.drop(\"BILL_AMT1\", axis=1), y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7NzCjU650XZ",
        "outputId": "3276dc21-5f52-4efa-82ce-91e13120090f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:02<00:00, 347.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8237    0.9476    0.8813       764\n",
            "           1     0.6694    0.3432    0.4538       236\n",
            "\n",
            "    accuracy                         0.8050      1000\n",
            "   macro avg     0.7465    0.6454    0.6675      1000\n",
            "weighted avg     0.7873    0.8050    0.7804      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_imputation_sklearn(clf, X_train, X_test.drop(\"BILL_AMT1\", axis=1), y_train, y_test, [\"BILL_AMT1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QtaVQnmbJTb",
        "outputId": "ea1404a9-4ee9-4ad3-c79a-747f0fc26bc4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [51:34<00:00,  3.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7822    0.9777    0.8691       764\n",
            "           1     0.6222    0.1186    0.1993       236\n",
            "\n",
            "    accuracy                         0.7750      1000\n",
            "   macro avg     0.7022    0.5482    0.5342      1000\n",
            "weighted avg     0.7444    0.7750    0.7110      1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "X_test_temp = X_test.drop([\"BILL_AMT1\", \"PAY_0\"], axis=1)\n",
        "predictions  = clf.predict(X_test_temp.reset_index(drop=True))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined"
      ],
      "metadata": {
        "id": "KQPxFS9b-ewD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NACq9qgAytSG",
        "outputId": "cae2e5fa-1757-4d78-9980-ad96ae511ac9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:03<00:00, 298.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8031    0.9503    0.8705       764\n",
            "           1     0.6042    0.2458    0.3494       236\n",
            "\n",
            "    accuracy                         0.7840      1000\n",
            "   macro avg     0.7036    0.5980    0.6100      1000\n",
            "weighted avg     0.7561    0.7840    0.7475      1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_smaller_model(X_train.drop([\"BILL_AMT1\", \"PAY_0\"], axis=1), X_test.drop([\"BILL_AMT1\", \"PAY_0\"], axis=1), y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAa83Hwj55rh",
        "outputId": "c137562f-336f-40cb-f3d7-cbe0ccd69b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 239.01it/s]\n",
            "100%|██████████| 1000/1000 [00:02<00:00, 352.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8191    0.4031    0.5404       764\n",
            "           1     0.2692    0.7119    0.3907       236\n",
            "\n",
            "    accuracy                         0.4760      1000\n",
            "   macro avg     0.5442    0.5575    0.4655      1000\n",
            "weighted avg     0.6894    0.4760    0.5050      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_imputation_credit(clf, X_train, X_test.drop([\"BILL_AMT1\", \"PAY_0\"], axis=1), y_train, y_test, [\"BILL_AMT1\", \"PAY_0\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ORvBfQtf6TY1",
        "6HbLlHfEsrHD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}