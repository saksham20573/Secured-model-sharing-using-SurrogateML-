{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "8gxjrwoW_Mjv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycl1rfOuNYgN",
        "outputId": "ece2adf9-f2ac-4765-e08d-e9880e5518af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "093l2xRbfanv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORvBfQtf6TY1"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Tn_WDgdVFx"
      },
      "outputs": [],
      "source": [
        "class TreeNode:\n",
        "  def __init__(self, best_split, X, y, left_node = None, right_node = None, left_prob = 0, right_prob = 0, isLeaf = False):\n",
        "    self.best_split = best_split\n",
        "    self.left_node = left_node\n",
        "    self.right_node = right_node\n",
        "    self.left_prob = left_prob\n",
        "    self.right_prob = right_prob\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.isLeaf = isLeaf\n",
        "\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None, randomWalkIter = 100):\n",
        "        self.max_depth = max_depth\n",
        "        self.randomWalkIter = randomWalkIter\n",
        "\n",
        "\n",
        "    def calculate_feature_importance(self):\n",
        "      n = self.randomWalkIter\n",
        "      self.importance_dict = {}\n",
        "      for i in self.train_features:\n",
        "        self.importance_dict[i] = 0\n",
        "\n",
        "      for _ in range(n):\n",
        "        self.run_random_walk()\n",
        "\n",
        "      for i in self.importance_dict.keys():\n",
        "        self.importance_dict[i] /= n\n",
        "\n",
        "    def run_random_walk(self):\n",
        "      steps = 0\n",
        "      temp = copy.deepcopy(self.importance_dict)\n",
        "      for i in temp.keys():\n",
        "        temp[i] = 0\n",
        "      tree = copy.deepcopy(self.treeNode)\n",
        "      while True:\n",
        "        if tree.isLeaf:\n",
        "          break\n",
        "        temp[self.train_features[tree.best_split[0]]] += 1\n",
        "        steps += 1\n",
        "        if tree.left_node != None and tree.right_node != None:\n",
        "          tree = random.choices([tree.left_node, tree.right_node], weights=[tree.left_prob, tree.right_prob])[0]\n",
        "        else:\n",
        "          tree = random.choice([tree.left_node, tree.right_node])\n",
        "      for i in self.importance_dict.keys():\n",
        "        self.importance_dict[i] += (temp[i] / steps)\n",
        "\n",
        "    def get_max_corr(self, X_train, y_train, feat):\n",
        "      df = X_train.copy()\n",
        "      df_in = X_train.copy()\n",
        "      y_train = y_train.copy()\n",
        "      drop_list = []\n",
        "      for i in df_in.columns:\n",
        "        if i not in self.prediction_feature_list and i != feat:\n",
        "          drop_list.append(i)\n",
        "\n",
        "      df = df.drop(drop_list, axis=1)\n",
        "      lst = dict(abs(df.corr()[feat]))\n",
        "      del lst[feat]\n",
        "      df = df.drop(feat, axis=1)\n",
        "      df['label'] = y_train\n",
        "      label_lst = dict(abs(df.corr()['label']))\n",
        "      del label_lst[\"label\"]\n",
        "\n",
        "\n",
        "      final_dict = {}\n",
        "      for i in lst:\n",
        "        final_dict[i] = lst[i] + label_lst[i]\n",
        "      sorted_corr = sorted(final_dict.items(), key = lambda x : x[1], reverse = True)\n",
        "      return sorted_corr\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      self.train_features = list(X.columns)\n",
        "      self.X_train = X.copy()\n",
        "      self.y_train = y.copy()\n",
        "      self.tree, self.treeNode = self._grow_tree(X.to_numpy(), y.to_numpy())\n",
        "      self.calculate_feature_importance()\n",
        "\n",
        "    def get_best_split(self, feature, X):\n",
        "      feature_idx = self.train_features.index(feature)\n",
        "      best_gini = np.inf\n",
        "      best_split = None\n",
        "      best_left_indices = None\n",
        "      best_right_indices = None\n",
        "      thresholds = np.unique(X[:, feature_idx])\n",
        "      for threshold in thresholds:\n",
        "          left_indices = np.where(X[:, feature_idx] <= threshold)[0]\n",
        "          right_indices = np.where(X[:, feature_idx] > threshold)[0]\n",
        "\n",
        "          if len(left_indices) == 0 or len(right_indices) == 0:\n",
        "              continue\n",
        "\n",
        "          gini = self._gini_impurity(y[left_indices], y[right_indices])\n",
        "\n",
        "          if gini < best_gini:\n",
        "              best_gini = gini\n",
        "              best_split = (feature_idx, threshold)\n",
        "              best_left_indices = left_indices\n",
        "              best_right_indices = right_indices\n",
        "      return best_split\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        num_samples, num_features = X.shape\n",
        "        num_classes = len(np.unique(y))\n",
        "\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or num_classes == 1:\n",
        "            final_class = int(np.bincount(y).argmax())\n",
        "            return final_class, TreeNode(final_class, X = X, y = y, isLeaf=True)\n",
        "        best_gini = np.inf\n",
        "        best_split = None\n",
        "        best_left_indices = None\n",
        "        best_right_indices = None\n",
        "\n",
        "        for feature_idx in range(num_features):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = np.where(X[:, feature_idx] <= threshold)[0]\n",
        "                right_indices = np.where(X[:, feature_idx] > threshold)[0]\n",
        "\n",
        "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
        "                    continue\n",
        "\n",
        "                gini = self._gini_impurity(y[left_indices], y[right_indices])\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_split = (feature_idx, threshold)\n",
        "                    best_left_indices = left_indices\n",
        "                    best_right_indices = right_indices\n",
        "\n",
        "        if best_gini == np.inf:\n",
        "            final_class = int(np.bincount(y).argmax())\n",
        "            return final_class, TreeNode(final_class, X = X, y = y, isLeaf=True)\n",
        "\n",
        "\n",
        "        left_subtree, leftNode = self._grow_tree(X[best_left_indices], y[best_left_indices], depth + 1)\n",
        "        right_subtree, rightNode = self._grow_tree(X[best_right_indices], y[best_right_indices], depth + 1)\n",
        "\n",
        "        currNode = TreeNode(best_split, X = X, y = y, left_node = leftNode, right_node = rightNode, left_prob = len(X[best_left_indices]) / len(X), right_prob = len(X[best_right_indices])/ len(X))\n",
        "\n",
        "        return (best_split, left_subtree, right_subtree), currNode\n",
        "\n",
        "    def _gini_impurity(self, left_y, right_y):\n",
        "        p_left = len(left_y) / (len(left_y) + len(right_y))\n",
        "        p_right = len(right_y) / (len(left_y) + len(right_y))\n",
        "        gini_left = 1 - sum((np.bincount(left_y) / len(left_y))**2)\n",
        "        gini_right = 1 - sum((np.bincount(right_y) / len(right_y))**2)\n",
        "        gini = p_left * gini_left + p_right * gini_right\n",
        "        return gini\n",
        "\n",
        "\n",
        "    def get_inp_count(self, inp, X_train):\n",
        "      drop_cols = []\n",
        "      X_train = X_train.reset_index(drop = True)\n",
        "      for i in list(X_train.columns):\n",
        "        if i not in self.prediction_feature_list:\n",
        "          drop_cols.append(i)\n",
        "      X_train = X_train.drop(drop_cols, axis=1)\n",
        "      occ_count = 0\n",
        "\n",
        "      for i in X_train.index:\n",
        "        flag = True\n",
        "        for col in list(inp.columns):\n",
        "          threshold = (max(X_train[col]) - min(X_train[col])) / 20\n",
        "          if abs(inp[col][0] - X_train[col][i]) > threshold:\n",
        "            flag = False\n",
        "            break\n",
        "        if flag:\n",
        "          occ_count += 1\n",
        "      return occ_count\n",
        "\n",
        "    def get_counts(self, inp, left_data, right_data, correlated_features):\n",
        "\n",
        "\n",
        "      left_count, right_count = 0, 0\n",
        "      iter = 0\n",
        "\n",
        "      drop_cols = []\n",
        "      left_data = left_data.reset_index(drop = True)\n",
        "      right_data = right_data.reset_index(drop = True)\n",
        "      for i in list(left_data.columns):\n",
        "        if i not in self.prediction_feature_list:\n",
        "          drop_cols.append(i)\n",
        "      left_data = left_data.drop(drop_cols, axis=1)\n",
        "      right_data = right_data.drop(drop_cols, axis=1)\n",
        "\n",
        "      inp_left = tuple(np.array(inp) / (left_data.max().to_numpy() - left_data.min().to_numpy() + 1e-10))\n",
        "      inp_right = tuple(np.array(inp) / (right_data.max().to_numpy()  - right_data.min().to_numpy() + 1e-10))\n",
        "      left_diff = np.abs(right_data - inp) / (left_data.max().to_numpy() - left_data.min().to_numpy() + 1e-10)\n",
        "      right_diff = np.abs(right_data - inp) / (right_data.max().to_numpy()  - right_data.min().to_numpy() + 1e-10)\n",
        "      tolerance = 0.05\n",
        "      out_left = (left_diff <= tolerance).all(axis=1)\n",
        "      out_right = (right_diff <= tolerance).all(axis=1)\n",
        "\n",
        "      left_count = out_left.sum()\n",
        "      right_count = out_right.sum()\n",
        "\n",
        "      return left_count + 1, right_count + 1\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "      self.prediction_feature_list = list(X.columns)\n",
        "      return np.array([self._predict_single(x, self.tree, self.treeNode, list(X.columns))[0] for x in tqdm(X.to_numpy())])\n",
        "\n",
        "    def _predict_single(self, x, tree, treeNode, inp_cols):\n",
        "        if isinstance(tree, int) or treeNode.isLeaf:\n",
        "            return tree, treeNode\n",
        "\n",
        "        feature_idx, threshold = tree[0]\n",
        "        best_feature_name = self.train_features[feature_idx]\n",
        "        inp_df = pd.DataFrame([list(x)], columns=self.prediction_feature_list)\n",
        "\n",
        "        # Logic to handle missing feature\n",
        "        if best_feature_name not in self.prediction_feature_list:\n",
        "          X_t = pd.DataFrame(treeNode.X, columns = self.train_features)\n",
        "          y_t = pd.Series(treeNode.y)\n",
        "          correlated_features = self.get_max_corr(X_t, y_t, best_feature_name)\n",
        "          left_weighted_sum = 0\n",
        "          right_weighted_sum  = 0\n",
        "          normalization_factor = 0\n",
        "          for feat, _ in correlated_features[:3]:\n",
        "            out = self.get_best_split(feat, treeNode.X)\n",
        "            if out == None:\n",
        "              continue\n",
        "            _, threshold = out\n",
        "            left_data = X_t[X_t[feat] <= threshold].reset_index(drop=True)\n",
        "            right_data = X_t[X_t[feat] > threshold].reset_index(drop=True)\n",
        "            dropped_x = list(x)\n",
        "            dropped_x.pop(inp_cols.index(feat))\n",
        "            left_count, right_count = self.get_counts(np.array(dropped_x), left_data.drop(feat, axis = 1), right_data.drop(feat, axis = 1), correlated_features)\n",
        "            left_weighted_sum += (self.importance_dict[feat]*left_count*treeNode.left_prob)\n",
        "            right_weighted_sum += (self.importance_dict[feat]*right_count*treeNode.right_prob)\n",
        "            normalization_factor += self.importance_dict[feat]\n",
        "\n",
        "          left_dec = left_weighted_sum / (normalization_factor + 1)\n",
        "          right_dec = right_weighted_sum / (normalization_factor + 1)\n",
        "\n",
        "          if left_dec >= right_dec:\n",
        "            return self._predict_single(x, tree[1], treeNode.left_node, inp_cols)\n",
        "          else:\n",
        "            return self._predict_single(x, tree[2], treeNode.right_node, inp_cols)\n",
        "\n",
        "        elif inp_df[best_feature_name][0] <= threshold:\n",
        "            return self._predict_single(x, tree[1], treeNode.left_node, inp_cols)\n",
        "        else:\n",
        "            return self._predict_single(x, tree[2], treeNode.right_node, inp_cols)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ-qMJ0ZmCdM"
      },
      "outputs": [],
      "source": [
        "def run_smaller_model(X_train, X_test, y_train, y_test):\n",
        "  model = DecisionTree(max_depth=5)\n",
        "  model.fit(X_train, y_train)\n",
        "  preds = model.predict(X_test)\n",
        "  print(classification_report(y_test, preds, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46L1li_gyvnE"
      },
      "outputs": [],
      "source": [
        "def run_imputation_model(model, X_train, X_test, y_train, y_test, dropped_columns):\n",
        "  X_test_final = X_test.copy()\n",
        "  while len(dropped_columns) != 0:\n",
        "    clf = DecisionTree(max_depth=5)\n",
        "    y_train_temp = X_train[dropped_columns[0]]\n",
        "    if min(y_train_temp) < 0:\n",
        "      y_train_temp += abs(min(y_train_temp))\n",
        "    X_train_temp = X_train.drop(dropped_columns, axis=1)\n",
        "    clf.fit(X_train_temp, y_train_temp)\n",
        "    X_test_final[dropped_columns[0]] = clf.predict(X_test_final)\n",
        "    dropped_columns.pop(0)\n",
        "  predictions = model.predict(X_test_final)\n",
        "  print(classification_report(y_test, predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4bqr2lMGxb5"
      },
      "outputs": [],
      "source": [
        "def run_imputation_sklearn(model, X_train, X_test, y_train, y_test, dropped_columns):\n",
        "    X_test_final = X_test.copy()\n",
        "    while len(dropped_columns) != 0:\n",
        "      clf = DecisionTreeRegressor(max_depth=3)\n",
        "      y_train_temp = X_train[dropped_columns[0]]\n",
        "      if min(y_train_temp) < 0:\n",
        "        y_train_temp += abs(min(y_train_temp))\n",
        "      X_train_temp = X_train.drop(dropped_columns, axis=1)\n",
        "      clf.fit(X_train_temp, y_train_temp)\n",
        "      X_test_final[dropped_columns[0]] = clf.predict(X_test_final)\n",
        "      dropped_columns.pop(0)\n",
        "    predictions = model.predict(X_test_final)\n",
        "    print(classification_report(y_test, predictions, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao8P2fCqPYfc"
      },
      "outputs": [],
      "source": [
        "def run_imputation_diabetes(model, X_train, X_test, y_train, y_test, dropped_columns):\n",
        "    X_test_final = X_test.copy()\n",
        "    while len(dropped_columns) != 0:\n",
        "      if dropped_columns[0] == \"diag_2\":\n",
        "        clf = DecisionTreeRegressor(max_depth=3)\n",
        "      else:\n",
        "        clf = DecisionTree(max_depth=3)\n",
        "      y_train_temp = X_train[dropped_columns[0]]\n",
        "      if min(y_train_temp) < 0:\n",
        "        y_train_temp += abs(min(y_train_temp))\n",
        "      X_train_temp = X_train.drop(dropped_columns, axis=1)\n",
        "      clf.fit(X_train_temp, y_train_temp)\n",
        "      X_test_final[dropped_columns[0]] = clf.predict(X_test_final)\n",
        "      dropped_columns.pop(0)\n",
        "    predictions = model.predict(X_test_final)\n",
        "    print(classification_report(y_test, predictions, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnKAOXD9-mL6"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Te-hHGKmJd7"
      },
      "outputs": [],
      "source": [
        "def print_tree(train_features, node):\n",
        "  if node.isLeaf:\n",
        "    return\n",
        "  else:\n",
        "    print(train_features[node.best_split[0]])\n",
        "    print_tree(train_features, node.left_node)\n",
        "    print_tree(train_features, node.right_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp1C8jkfhZv6"
      },
      "source": [
        "## Diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpoJgFnY3Zz1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetic_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmQSjPeycONV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetic_data.csv\")\n",
        "label = 'readmitted'\n",
        "\n",
        "df = df.drop([\"weight\", 'patient_nbr', 'encounter_id', 'max_glu_serum', 'A1Cresult'] , axis = 1)\n",
        "df = df.dropna()\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "for column in df.select_dtypes(include='object'):\n",
        "  df[column] = le.fit_transform(df[column])\n",
        "  df[column] += 1\n",
        "\n",
        "\n",
        "X = df.drop(label, axis=1)\n",
        "y = df[label]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1mwx-wZeQPG",
        "outputId": "86aced49-3b3b-4937-e25a-76943e7706fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['race', 'gender', 'age', 'admission_type_id',\n",
              "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
              "       'payer_code', 'medical_specialty', 'num_lab_procedures',\n",
              "       'num_procedures', 'num_medications', 'number_outpatient',\n",
              "       'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3',\n",
              "       'number_diagnoses', 'metformin', 'repaglinide', 'nateglinide',\n",
              "       'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide',\n",
              "       'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
              "       'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton',\n",
              "       'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
              "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
              "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nRjo65DgTyZ"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTree(max_depth=7)\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGXc3x4heT0q"
      },
      "outputs": [],
      "source": [
        "X_test = X_test.iloc[:1000, :]\n",
        "y_test = y_test[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY3e0Gg6lbG6",
        "outputId": "5924bf3e-b311-4349-8439-0ece3069d793"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([39,  1, 20, 13,  5, 64, 29, 14, 62, 21, 30, 49, 10, 53, 66, 24, 26,\n",
              "       35, 17, 32, 63, 37, 11, 73, 51, 43, 22,  4, 55, 40, 52, 47, 15, 27,\n",
              "       42, 68, 70, 69, 28, 67, 38, 45, 19,  3, 57,  2, 65, 41, 36,  8, 60,\n",
              "       71, 31, 50, 61, 46, 16, 48, 25, 72, 54, 34,  9, 59, 58, 18, 33,  6,\n",
              "       44, 23, 12,  7, 56])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df.medical_specialty.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve8S0f7NxeIQ",
        "outputId": "9bb61f7d-6dcd-4829-9c62-1ab29e4306a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number_inpatient\n",
            "number_diagnoses\n",
            "admission_source_id\n",
            "number_outpatient\n",
            "admission_source_id\n",
            "num_procedures\n",
            "num_medications\n",
            "num_lab_procedures\n",
            "insulin\n",
            "discharge_disposition_id\n",
            "discharge_disposition_id\n",
            "num_procedures\n",
            "time_in_hospital\n",
            "age\n",
            "race\n",
            "age\n",
            "diag_1\n",
            "diag_2\n",
            "age\n",
            "number_emergency\n",
            "admission_type_id\n",
            "num_medications\n",
            "admission_type_id\n",
            "diag_3\n",
            "number_emergency\n",
            "insulin\n",
            "diabetesMed\n",
            "admission_type_id\n",
            "number_emergency\n",
            "diag_3\n",
            "discharge_disposition_id\n",
            "age\n",
            "discharge_disposition_id\n",
            "discharge_disposition_id\n",
            "number_outpatient\n",
            "number_emergency\n",
            "diabetesMed\n",
            "discharge_disposition_id\n",
            "age\n",
            "number_diagnoses\n",
            "diag_2\n",
            "medical_specialty\n",
            "num_lab_procedures\n",
            "discharge_disposition_id\n",
            "age\n",
            "payer_code\n",
            "age\n",
            "diag_1\n",
            "num_medications\n",
            "discharge_disposition_id\n",
            "diag_3\n",
            "medical_specialty\n",
            "glimepiride\n",
            "num_lab_procedures\n",
            "gender\n",
            "payer_code\n",
            "admission_type_id\n",
            "discharge_disposition_id\n",
            "diag_1\n",
            "medical_specialty\n",
            "discharge_disposition_id\n",
            "admission_type_id\n",
            "number_inpatient\n",
            "discharge_disposition_id\n",
            "admission_source_id\n",
            "admission_source_id\n",
            "num_lab_procedures\n",
            "number_diagnoses\n",
            "number_outpatient\n",
            "discharge_disposition_id\n",
            "number_diagnoses\n",
            "num_lab_procedures\n",
            "num_medications\n",
            "number_emergency\n",
            "diag_3\n",
            "diag_1\n",
            "medical_specialty\n",
            "diag_1\n",
            "admission_type_id\n",
            "discharge_disposition_id\n",
            "discharge_disposition_id\n",
            "discharge_disposition_id\n",
            "medical_specialty\n",
            "discharge_disposition_id\n",
            "discharge_disposition_id\n",
            "diag_3\n",
            "race\n",
            "diag_3\n",
            "time_in_hospital\n",
            "payer_code\n",
            "age\n",
            "medical_specialty\n",
            "discharge_disposition_id\n",
            "number_inpatient\n",
            "number_outpatient\n",
            "admission_source_id\n",
            "admission_source_id\n",
            "discharge_disposition_id\n",
            "diag_1\n",
            "num_medications\n",
            "payer_code\n",
            "number_inpatient\n",
            "number_emergency\n",
            "diag_3\n",
            "diag_1\n",
            "diag_3\n",
            "diag_2\n",
            "medical_specialty\n",
            "discharge_disposition_id\n",
            "discharge_disposition_id\n",
            "payer_code\n",
            "num_medications\n",
            "discharge_disposition_id\n",
            "diag_1\n",
            "age\n",
            "num_procedures\n",
            "insulin\n",
            "time_in_hospital\n",
            "number_inpatient\n",
            "num_medications\n",
            "diag_1\n"
          ]
        }
      ],
      "source": [
        "print_tree(clf.train_features, clf.treeNode)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original Model"
      ],
      "metadata": {
        "id": "tmszqm9CCC41"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaAoZ89HgtY6",
        "outputId": "273545d5-2e6b-45ce-a871-bc1cc730a593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:06<00:00, 150.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000       108\n",
            "           2     0.4534    0.3040    0.3639       352\n",
            "           3     0.5887    0.8296    0.6887       540\n",
            "\n",
            "    accuracy                         0.5550      1000\n",
            "   macro avg     0.3474    0.3779    0.3509      1000\n",
            "weighted avg     0.4775    0.5550    0.5000      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "predictions  = clf.predict(X_test)\n",
        "print(classification_report(y_test, predictions, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary"
      ],
      "metadata": {
        "id": "KDgKGWcTCJGt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-cN1-_IhklC",
        "outputId": "b9a4f5e2-a1a5-4fea-8609-61abc642a0a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [02:04<00:00,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000       108\n",
            "           2     0.4534    0.3040    0.3639       352\n",
            "           3     0.5887    0.8296    0.6887       540\n",
            "\n",
            "    accuracy                         0.5550      1000\n",
            "   macro avg     0.3474    0.3779    0.3509      1000\n",
            "weighted avg     0.4775    0.5550    0.5000      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "X_test_temp = X_test.drop(\"diabetesMed\", axis=1)\n",
        "predictions  = clf.predict(X_test_temp.reset_index(drop=True))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR-qnR1QgHSK",
        "outputId": "70b0d452-1968-4925-ceec-f630d80ecbc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 218.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.3333    0.0093    0.0180       108\n",
            "           2     0.4585    0.2983    0.3614       352\n",
            "           3     0.5859    0.8333    0.6881       540\n",
            "\n",
            "    accuracy                         0.5560      1000\n",
            "   macro avg     0.4593    0.3803    0.3558      1000\n",
            "weighted avg     0.5138    0.5560    0.5007      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_smaller_model(X_train.drop(\"diabetesMed\", axis=1), X_test.drop(\"diabetesMed\", axis=1), y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbxrCfv2gHSX",
        "outputId": "6b6a93e2-a243-4c28-b3ba-59f80321f559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:02<00:00, 368.25it/s]\n",
            "100%|██████████| 1000/1000 [00:06<00:00, 153.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000       108\n",
            "           2     0.4534    0.3040    0.3639       352\n",
            "           3     0.5887    0.8296    0.6887       540\n",
            "\n",
            "    accuracy                         0.5550      1000\n",
            "   macro avg     0.3474    0.3779    0.3509      1000\n",
            "weighted avg     0.4775    0.5550    0.5000      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_imputation_model(clf, X_train, X_test.drop(\"diabetesMed\", axis=1), y_train, y_test, [\"diabetesMed\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ordinal"
      ],
      "metadata": {
        "id": "yQKFZYIDCMv3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUlgtrvnjjxe",
        "outputId": "14476d5f-af81-47a7-add2-24a662b8ebde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:42<00:00, 23.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000       108\n",
            "           2     0.4484    0.3210    0.3742       352\n",
            "           3     0.5919    0.8167    0.6864       540\n",
            "\n",
            "    accuracy                         0.5540      1000\n",
            "   macro avg     0.3468    0.3792    0.3535      1000\n",
            "weighted avg     0.4775    0.5540    0.5024      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "X_test_temp = X_test.drop(\"num_lab_procedures\", axis=1)\n",
        "predictions  = clf.predict(X_test_temp.reset_index(drop=True))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpETUqGhgXAH",
        "outputId": "177e7679-81eb-4831-fb64-4e8879c4caf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:06<00:00, 160.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.3333    0.0093    0.0180       108\n",
            "           2     0.4839    0.2557    0.3346       352\n",
            "           3     0.5832    0.8759    0.7002       540\n",
            "\n",
            "    accuracy                         0.5640      1000\n",
            "   macro avg     0.4668    0.3803    0.3509      1000\n",
            "weighted avg     0.5213    0.5640    0.4978      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_smaller_model(X_train.drop(\"num_lab_procedures\", axis=1), X_test.drop(\"num_lab_procedures\", axis=1), y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tADHrCURgXAT",
        "outputId": "857385eb-b4b9-4ec7-9fc8-08b293d1ac4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:05<00:00, 185.15it/s]\n",
            "100%|██████████| 1000/1000 [00:06<00:00, 147.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000       108\n",
            "           2     0.4569    0.3011    0.3630       352\n",
            "           3     0.5856    0.8296    0.6866       540\n",
            "\n",
            "    accuracy                         0.5540      1000\n",
            "   macro avg     0.3475    0.3769    0.3499      1000\n",
            "weighted avg     0.4771    0.5540    0.4985      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_imputation_model(clf, X_train, X_test.drop(\"num_lab_procedures\", axis=1), y_train, y_test, [\"num_lab_procedures\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numeric"
      ],
      "metadata": {
        "id": "dlpyQp5aCUGr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ62qjwzkI-P",
        "outputId": "f4c77373-d6d3-4683-8158-dc5c13b31d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:15<00:00, 66.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000       108\n",
            "           2     0.4576    0.3068    0.3673       352\n",
            "           3     0.5892    0.8315    0.6897       540\n",
            "\n",
            "    accuracy                         0.5570      1000\n",
            "   macro avg     0.3490    0.3794    0.3524      1000\n",
            "weighted avg     0.4793    0.5570    0.5017      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_test_temp = X_test.drop(\"diag_2\", axis=1)\n",
        "predictions  = clf.predict(X_test_temp.reset_index(drop=True))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMak36lRgakS",
        "outputId": "95bbb7cc-1bf9-4832-c379-a957f12b7ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 217.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.3333    0.0093    0.0180       108\n",
            "           2     0.4585    0.2983    0.3614       352\n",
            "           3     0.5859    0.8333    0.6881       540\n",
            "\n",
            "    accuracy                         0.5560      1000\n",
            "   macro avg     0.4593    0.3803    0.3558      1000\n",
            "weighted avg     0.5138    0.5560    0.5007      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_smaller_model(X_train.drop(\"diag_2\", axis=1), X_test.drop(\"diag_2\", axis=1), y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi1JxQ4zgakd",
        "outputId": "50ed5527-696a-4bea-8470-1d804f6b499b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:11<00:00, 87.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000       108\n",
            "           2     0.4557    0.3068    0.3667       352\n",
            "           3     0.5887    0.8296    0.6887       540\n",
            "\n",
            "    accuracy                         0.5560      1000\n",
            "   macro avg     0.3481    0.3788    0.3518      1000\n",
            "weighted avg     0.4783    0.5560    0.5010      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_imputation_sklearn(clf, X_train, X_test.drop(\"diag_2\", axis=1), y_train, y_test, [\"diag_2\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined"
      ],
      "metadata": {
        "id": "N6TY2boHCWG4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jZm8IGMO9DW",
        "outputId": "65f2c871-90c6-4c0a-d000-512d52e15b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:46<00:00,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000       108\n",
            "           2     0.4524    0.3239    0.3775       352\n",
            "           3     0.5925    0.8185    0.6874       540\n",
            "\n",
            "    accuracy                         0.5560      1000\n",
            "   macro avg     0.3483    0.3808    0.3550      1000\n",
            "weighted avg     0.4792    0.5560    0.5041      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "X_test_temp = X_test.drop([\"diag_2\", \"num_lab_procedures\", \"diabetesMed\"], axis=1)\n",
        "predictions  = clf.predict(X_test_temp.reset_index(drop=True))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_auOCsKO9DX",
        "outputId": "a300ab3e-8a4f-4863-e28f-51780b2aab4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 218.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.3333    0.0093    0.0180       108\n",
            "           2     0.4839    0.2557    0.3346       352\n",
            "           3     0.5832    0.8759    0.7002       540\n",
            "\n",
            "    accuracy                         0.5640      1000\n",
            "   macro avg     0.4668    0.3803    0.3509      1000\n",
            "weighted avg     0.5213    0.5640    0.4978      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_smaller_model(X_train.drop([\"diag_2\", \"num_lab_procedures\", \"diabetesMed\"], axis=1), X_test.drop([\"diag_2\", \"num_lab_procedures\", \"diabetesMed\"], axis=1), y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4Q79A-vO9DY",
        "outputId": "ee27b91d-47b2-4033-9917-39c78911f765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:02<00:00, 373.32it/s]\n",
            "100%|██████████| 1000/1000 [00:01<00:00, 585.83it/s]\n",
            "100%|██████████| 1000/1000 [00:07<00:00, 127.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.0000    0.0000    0.0000       108\n",
            "           2     0.4534    0.3040    0.3639       352\n",
            "           3     0.5840    0.8241    0.6836       540\n",
            "\n",
            "    accuracy                         0.5520      1000\n",
            "   macro avg     0.3458    0.3760    0.3492      1000\n",
            "weighted avg     0.4749    0.5520    0.4972      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "run_imputation_diabetes(clf, X_train, X_test.drop([\"diag_2\", \"num_lab_procedures\", \"diabetesMed\"], axis=1), y_train, y_test, [\"diag_2\", \"num_lab_procedures\", \"diabetesMed\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ORvBfQtf6TY1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}